LOG_LEVEL=DEBUG
EMBEDDING_DIMENSION=1536

SCRAPER_PROVIDER=crawl4ai
SCRAPER_API_HOST=http://127.0.0.1:11235
SCRAPER_API_KEY=
SCRAPER_POLLING_INTERVAL=2.0
SCRAPER_REQUEST_TIMEOUT=60.0
SCRAPER_DEFAULT_JOB_TIMEOUT=300.0
SCRAPER_MAX_CONCURRENT_JOBS_OVERRIDE=10

POSTGRES_HOST=127.0.0.1
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=docu_ai
POSTGRES_POOL_SIZE=5
POSTGRES_MAX_OVERFLOW=10
POSTGRES_ECHO=false

EMBEDDING_PROVIDER=openai
EMBEDDING_OPENAI_API_KEY=your_openai_api_key_here # IMPORTANT: Set this!
EMBEDDING_OPENAI_MODEL=text-embedding-3-small     # Or text-embedding-ada-002, etc.
# EMBEDDING_OPENAI_MODEL=text-embedding-ada-002
# -- HuggingFace Settings (if provider=huggingface) --
# Use model name from HF Hub or local path
EMBEDDING_HUGGINGFACE_MODEL=sentence-transformers/all-MiniLM-L6-v2
# EMBEDDING_HUGGINGFACE_MODEL=sentence-transformers/multi-qa-MiniLM-L6-cos-v1
# Device: cpu, cuda, mps, auto
EMBEDDING_HUGGINGFACE_DEVICE=auto
# -- Ollama Settings (if provider=ollama) --
EMBEDDING_OLLAMA_HOST=http://localhost:11434 # Your Ollama server address
EMBEDDING_OLLAMA_MODEL=nomic-embed-text      # Ensure this model is pulled in Ollama
EMBEDDING_DIMENSION=1536                     # IMPORTANT: Must match the dimension of EMBEDDING_OPENAI_MODEL (1536 for text-embedding-3-small/ada-002)
EMBEDDING_BATCH_SIZE=32

LLM_COMPLETION_MODEL=ollama/llama3.1
LLM_COMPLETION_API_BASE=http://localhost:11434
LLM_COMPLETION_TEMPERATURE=0.1
LLM_COMPLETION_MAX_TOKENS=256
LLM_COMPLETION_TIMEOUT=600.0

OLLAMA_API_BASE=http://localhost:11434
OPENROUTER_API_KEY=

# --- API KEYS FOR LiteLLM ---
# LiteLLM automatically reads API keys from standard environment variables.
# Set the keys corresponding to the provider used in COMPLETION_MODEL.
# Examples:
# OPENAI_API_KEY=your_openai_key_here
# ANTHROPIC_API_KEY=your_anthropic_key_here
# COHERE_API_KEY=your_cohere_key_here
# AZURE_API_KEY=your_azure_openai_key_here
# AZURE_API_BASE=your_azure_openai_endpoint # Needs COMPLETION_API_BASE or this env var
# AZURE_API_VERSION=your_azure_api_version # Needs this env var for Azure
# HUGGINGFACE_API_KEY=your_hf_key_for_inference_endpoints
# GEMINI_API_KEY=your_google_gemini_key
# Add other keys as needed based on LiteLLM documentation.
# For Ollama (running locally), no API key is typically needed.
