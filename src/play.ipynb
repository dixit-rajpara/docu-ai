{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from config.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_page(url: str) -> str:\n",
    "    token = settings.crawler.api_key.get_secret_value()\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    # Basic crawl with authentication\n",
    "    response = requests.post(\n",
    "        f\"{settings.crawler.api_host}/crawl\",\n",
    "        headers=headers,\n",
    "        json={\n",
    "            \"urls\": url,\n",
    "            \"priority\": 10,\n",
    "        },\n",
    "    )\n",
    "    return response.json()[\"task_id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = crawl_page(\"https://docs.crawl4ai.com/core/docker-deployment/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_result(task_id: str) -> str:\n",
    "    token = settings.crawler.api_key.get_secret_value()\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "    return requests.get(\n",
    "        f\"{settings.crawler.api_host}/task/{task_id}\",\n",
    "        headers=headers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_task_result(task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content = result.json()[\"result\"][\"cleaned_html\"]\n",
    "print(len(html_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import html2text\n",
    "from IPython.display import display, HTML, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(soup: BeautifulSoup):\n",
    "    # Remove tags but keep their content\n",
    "    for tag in soup.find_all([\"a\"]):\n",
    "        tag.unwrap()\n",
    "\n",
    "    # Remove whole tags and their content\n",
    "    for tag_name in [\n",
    "        \"script\",\n",
    "        \"style\",\n",
    "        \"noscript\",\n",
    "        \"iframe\",\n",
    "        \"canvas\",\n",
    "        \"svg\",\n",
    "        \"object\",\n",
    "        \"embed\",\n",
    "        \"form\",\n",
    "        \"input\",\n",
    "        \"button\",\n",
    "        \"nav\",\n",
    "        \"footer\",\n",
    "        \"header\",\n",
    "        \"aside\",\n",
    "        \"video\",\n",
    "        \"audio\",\n",
    "    ]:\n",
    "        for tag in soup.find_all(tag_name):\n",
    "            tag.decompose()\n",
    "\n",
    "    # Remove empty lists\n",
    "    for list_tag in soup.find_all([\"ul\", \"ol\"]):\n",
    "        li_items = list_tag.find_all(\"li\")\n",
    "        has_non_empty_item = any(li.get_text(strip=True) for li in li_items)\n",
    "        if not li_items or not has_non_empty_item:\n",
    "            list_tag.decompose()\n",
    "            \n",
    "    for img in soup.find_all('img'):\n",
    "        alt_text = img.get('alt')\n",
    "        if alt_text:\n",
    "            img.replace_with(alt_text)\n",
    "        else:\n",
    "            img.decompose()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def html_to_markdown(html: str) -> str:\n",
    "    converter = html2text.HTML2Text()\n",
    "    converter.ignore_links = True\n",
    "    converter.ignore_images = True\n",
    "    converter.body_width = 0\n",
    "    return converter.handle(html).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_markdown_to_file(markdown_text: str, file_path: str) -> None:\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(markdown_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "clean_html(soup)\n",
    "markdown_content = html_to_markdown(str(soup))\n",
    "# display(HTML(str(soup)))\n",
    "display(Markdown(markdown_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_markdown_to_file(markdown_content, \"../docs/crawl4ai_docker_deployment.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
